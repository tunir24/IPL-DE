{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["Databricks notebook source"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["spark"]}, {"cell_type": "markdown", "metadata": {}, "source": ["COMMAND ----------"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from pyspark.sql.types import StructField, StructType, IntegerType, StringType, BooleanType, DateType, DecimalType\n", "from pyspark.sql.functions import col, when, sum, avg, row_number \n", "from pyspark.sql.window import Window\n", "     "]}, {"cell_type": "markdown", "metadata": {}, "source": ["COMMAND ----------"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from pyspark.sql import SparkSession"]}, {"cell_type": "markdown", "metadata": {}, "source": ["COMMAND ----------"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["spark = SparkSession.builder.appName(\"IPL_DE\").getOrCreate()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["COMMAND ----------"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["spark"]}, {"cell_type": "markdown", "metadata": {}, "source": ["COMMAND ----------"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df=spark.read.csv(\"s3://ipl-data-analysis-project/Ball_By_Ball.csv\",header=True,inferSchema=True)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["COMMAND ----------"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["COMMAND ----------"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df.printSchema()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["COMMAND ----------"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df.display()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["COMMAND ----------"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["ball_by_ball_schema = StructType([\n", "    StructField(\"match_id\", IntegerType(), True),\n", "    StructField(\"over_id\", IntegerType(), True),\n", "    StructField(\"ball_id\", IntegerType(), True),\n", "    StructField(\"innings_no\", IntegerType(), True),\n", "    StructField(\"team_batting\", StringType(), True),\n", "    StructField(\"team_bowling\", StringType(), True),\n", "    StructField(\"striker_batting_position\", IntegerType(), True),\n", "    StructField(\"extra_type\", StringType(), True),\n", "    StructField(\"runs_scored\", IntegerType(), True),\n", "    StructField(\"extra_runs\", IntegerType(), True),\n", "    StructField(\"wides\", IntegerType(), True),\n", "    StructField(\"legbyes\", IntegerType(), True),\n", "    StructField(\"byes\", IntegerType(), True),\n", "    StructField(\"noballs\", IntegerType(), True),\n", "    StructField(\"penalty\", IntegerType(), True),\n", "    StructField(\"bowler_extras\", IntegerType(), True),\n", "    StructField(\"out_type\", StringType(), True),\n", "    StructField(\"caught\", BooleanType(), True),\n", "    StructField(\"bowled\", BooleanType(), True),\n", "    StructField(\"run_out\", BooleanType(), True),\n", "    StructField(\"lbw\", BooleanType(), True),\n", "    StructField(\"retired_hurt\", BooleanType(), True),\n", "    StructField(\"stumped\", BooleanType(), True),\n", "    StructField(\"caught_and_bowled\", BooleanType(), True),\n", "    StructField(\"hit_wicket\", BooleanType(), True),\n", "    StructField(\"obstructingfeild\", BooleanType(), True),\n", "    StructField(\"bowler_wicket\", BooleanType(), True),\n", "    StructField(\"match_date\", DateType(), True),\n", "    StructField(\"season\", IntegerType(), True),\n", "    StructField(\"striker\", IntegerType(), True),\n", "    StructField(\"non_striker\", IntegerType(), True),\n", "    StructField(\"bowler\", IntegerType(), True),\n", "    StructField(\"player_out\", IntegerType(), True),\n", "    StructField(\"fielders\", IntegerType(), True),\n", "    StructField(\"striker_match_sk\", IntegerType(), True),\n", "    StructField(\"strikersk\", IntegerType(), True),\n", "    StructField(\"nonstriker_match_sk\", IntegerType(), True),\n", "    StructField(\"nonstriker_sk\", IntegerType(), True),\n", "    StructField(\"fielder_match_sk\", IntegerType(), True),\n", "    StructField(\"fielder_sk\", IntegerType(), True),\n", "    StructField(\"bowler_match_sk\", IntegerType(), True),\n", "    StructField(\"bowler_sk\", IntegerType(), True),\n", "    StructField(\"playerout_match_sk\", IntegerType(), True),\n", "    StructField(\"battingteam_sk\", IntegerType(), True),\n", "    StructField(\"bowlingteam_sk\", IntegerType(), True),\n", "    StructField(\"keeper_catch\", BooleanType(), True),\n", "    StructField(\"player_out_sk\", IntegerType(), True),\n", "    StructField(\"matchdatesk\", DateType(), True)\n", "])\n", "     "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["ball_by_ball_df = spark.read.schema(ball_by_ball_schema).format(\"csv\").option(\"header\",\"true\").load(\"s3://ipl-data-analysis-project/Ball_By_Ball.csv\")\n", "     "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["match_schema = StructType([\n", "    StructField(\"match_sk\", IntegerType(), True),\n", "    StructField(\"match_id\", IntegerType(), True),\n", "    StructField(\"team1\", StringType(), True),\n", "    StructField(\"team2\", StringType(), True),\n", "    StructField(\"match_date\", DateType(), True),\n", "    StructField(\"season_year\", IntegerType(), True),\n", "    StructField(\"venue_name\", StringType(), True),\n", "    StructField(\"city_name\", StringType(), True),\n", "    StructField(\"country_name\", StringType(), True),\n", "    StructField(\"toss_winner\", StringType(), True),\n", "    StructField(\"match_winner\", StringType(), True),\n", "    StructField(\"toss_name\", StringType(), True),\n", "    StructField(\"win_type\", StringType(), True),\n", "    StructField(\"outcome_type\", StringType(), True),\n", "    StructField(\"manofmach\", StringType(), True),\n", "    StructField(\"win_margin\", IntegerType(), True),\n", "    StructField(\"country_id\", IntegerType(), True)\n", "])\n", "match_df = spark.read.schema(match_schema).format(\"csv\").option(\"header\",\"true\").load(\"s3://ipl-data-analysis-project/Match.csv\")\n", "     "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["player_schema = StructType([\n", "    StructField(\"player_sk\", IntegerType(), True),\n", "    StructField(\"player_id\", IntegerType(), True),\n", "    StructField(\"player_name\", StringType(), True),\n", "    StructField(\"dob\", DateType(), True),\n", "    StructField(\"batting_hand\", StringType(), True),\n", "    StructField(\"bowling_skill\", StringType(), True),\n", "    StructField(\"country_name\", StringType(), True)\n", "])"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["player_df = spark.read.schema(player_schema).format(\"csv\").option(\"header\",\"true\").load(\"s3://ipl-data-analysis-project/Player.csv\")\n", "     "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["player_match_schema = StructType([\n", "    StructField(\"player_match_sk\", IntegerType(), True),\n", "    StructField(\"playermatch_key\", DecimalType(), True),\n", "    StructField(\"match_id\", IntegerType(), True),\n", "    StructField(\"player_id\", IntegerType(), True),\n", "    StructField(\"player_name\", StringType(), True),\n", "    StructField(\"dob\", DateType(), True),\n", "    StructField(\"batting_hand\", StringType(), True),\n", "    StructField(\"bowling_skill\", StringType(), True),\n", "    StructField(\"country_name\", StringType(), True),\n", "    StructField(\"role_desc\", StringType(), True),\n", "    StructField(\"player_team\", StringType(), True),\n", "    StructField(\"opposit_team\", StringType(), True),\n", "    StructField(\"season_year\", IntegerType(), True),\n", "    StructField(\"is_manofthematch\", BooleanType(), True),\n", "    StructField(\"age_as_on_match\", IntegerType(), True),\n", "    StructField(\"isplayers_team_won\", BooleanType(), True),\n", "    StructField(\"batting_status\", StringType(), True),\n", "    StructField(\"bowling_status\", StringType(), True),\n", "    StructField(\"player_captain\", StringType(), True),\n", "    StructField(\"opposit_captain\", StringType(), True),\n", "    StructField(\"player_keeper\", StringType(), True),\n", "    StructField(\"opposit_keeper\", StringType(), True)\n", "])"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["player_match_df = spark.read.schema(player_match_schema).format(\"csv\").option(\"header\",\"true\").load(\"s3://ipl-data-analysis-project/Player_match.csv\")\n", "     "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["team_schema = StructType([\n", "    StructField(\"team_sk\", IntegerType(), True),\n", "    StructField(\"team_id\", IntegerType(), True),\n", "    StructField(\"team_name\", StringType(), True)\n", "])"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["team_df = spark.read.schema(team_schema).format(\"csv\").option(\"header\",\"true\").load(\"s3://ipl-data-analysis-project/Team.csv\")\n", "     "]}, {"cell_type": "markdown", "metadata": {}, "source": ["COMMAND ----------"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Without Extra"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df_new = ball_by_ball_df.filter((col(\"wides\")==0) & (col(\"noballs\")==0))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["COMMAND ----------"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Total Runs & Average Runs Scored by each team in each innings"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df_new.groupBy(\"match_id\",\"innings_no\").agg(sum(\"runs_scored\").alias(\"Total runs\"),avg(\"runs_scored\").alias(\"Avg Runs\")).orderBy(\"match_id\").show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["COMMAND ----------"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df_new.display(5)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["COMMAND ----------"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Window Function: Calculate running total of runs in each match for each over"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["windowSpec = Window.partitionBy(\"match_id\",\"innings_no\").orderBy(\"over_id\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["ball_by_ball_df = ball_by_ball_df.withColumn(\n", "    \"running_total_runs\",\n", "    sum(\"runs_scored\").over(windowSpec)\n", ")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["ball_by_ball_df.display()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["COMMAND ----------"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Impact Balls"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["ball_by_ball_df = ball_by_ball_df.withColumn(\n", "    \"Impactful Over\",when((col(\"runs_scored\")+col(\"extra_runs\")>=6) | (col(\"bowler_wicket\")==True),True).otherwise(False)\n", ")\n", "ball_by_ball_df.display()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["COMMAND ----------"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from pyspark.sql.functions import year, month, dayofmonth, when"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Extracting year, month, and day from the match date for more detailed time-based analysis"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["match_df = match_df.withColumn(\"year\", year(\"match_date\"))\n", "match_df = match_df.withColumn(\"month\", month(\"match_date\"))\n", "match_df = match_df.withColumn(\"day\", dayofmonth(\"match_date\"))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["High margin win: categorizing win margins into 'high', 'medium', and 'low'"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["match_df = match_df.withColumn(\n", "    \"win_margin_category\",\n", "    when(col(\"win_margin\") >= 100, \"High\")\n", "    .when((col(\"win_margin\") >= 50) & (col(\"win_margin\") < 100), \"Medium\")\n", "    .otherwise(\"Low\")\n", ")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Analyze the impact of the toss: who wins the toss and the match"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["match_df = match_df.withColumn(\n", "    \"toss_match_winner\",\n", "    when(col(\"toss_winner\") == col(\"match_winner\"), \"Yes\").otherwise(\"No\")\n", ")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["COMMAND ----------"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from pyspark.sql.functions import lower, regexp_replace"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Normalize and clean player names"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["player_df = player_df.withColumn(\"player_name\", lower(regexp_replace(\"player_name\", \"[^a-zA-Z0-9 ]\", \"\")))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Handle missing values in 'batting_hand' and 'bowling_skill' with a default 'unknown'"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["player_df = player_df.na.fill({\"batting_hand\": \"unknown\", \"bowling_skill\": \"unknown\"})"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Categorizing players based on batting hand"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["player_df = player_df.withColumn(\n", "    \"batting_style\",\n", "    when(col(\"batting_hand\").contains(\"left\"), \"Left-Handed\").otherwise(\"Right-Handed\")\n", ")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Show the modified player DataFrame"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["player_df.show(2)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["COMMAND ----------"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from pyspark.sql.functions import col, when, current_date, expr"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Add a 'veteran_status' column based on player age"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["player_match_df = player_match_df.withColumn(\n", "    \"veteran_status\",\n", "    when(col(\"age_as_on_match\") >= 35, \"Veteran\").otherwise(\"Non-Veteran\")\n", ")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Dynamic column to calculate years since debut"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["player_match_df = player_match_df.withColumn(\n", "    \"years_since_debut\",\n", "    (year(current_date()) - col(\"season_year\"))\n", ")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Show the enriched DataFrame"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["player_match_df.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["COMMAND ----------"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["ball_by_ball_df.createOrReplaceTempView(\"ball_by_ball\")\n", "match_df.createOrReplaceTempView(\"match\")\n", "player_df.createOrReplaceTempView(\"player\")\n", "player_match_df.createOrReplaceTempView(\"player_match\")\n", "team_df.createOrReplaceTempView(\"team\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["COMMAND ----------"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["player_match_df.display(5)\n", "match_df.display(5)\n", "ball_by_ball_df.display(5)\n", "player_df.display(5)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["COMMAND ----------"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["match_df.display(5)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["COMMAND ----------"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["player_match_df.display(5)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["COMMAND ----------"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Top scorers of seasons"]}, {"cell_type": "markdown", "metadata": {}, "source": ["top_scorer = spark.sql(\n<br>\n", "select pm.player_name,m.season_year,sum(runs_scored) as runs from ball_by_ball b join match m on b.match_id=m.match_id<br>\n", "                       join player_match pm on b.striker = pm.player_id and b.match_id=pm.match_id<br>\n", "                       group by pm.player_name , m.season_year order by runs desc<br>\n", "                     \n)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["COMMAND ----------"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["top_scorer.display(5)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["COMMAND ----------"]}, {"cell_type": "markdown", "metadata": {}, "source": ["economical_bowlers_powerplay = spark.sql(\n<br>\n", "SELECT <br>\n", "    p.player_name, <br>\n", "    AVG(b.runs_scored) AS avg_runs_per_ball, <br>\n", "    COUNT(b.bowler_wicket) AS total_wickets<br>\n", "FROM ball_by_ball b<br>\n", "JOIN player_match pm ON b.match_id = pm.match_id AND b.bowler = pm.player_id<br>\n", "JOIN player p ON pm.player_id = p.player_id<br>\n", "WHERE b.over_id <= 6<br>\n", "GROUP BY p.player_name<br>\n", "HAVING COUNT(*) >= 1<br>\n", "ORDER BY avg_runs_per_ball ASC, total_wickets DESC<br>\n", ""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["economical_bowlers_powerplay.display()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["COMMAND ----------"]}, {"cell_type": "markdown", "metadata": {}, "source": ["toss_impact_individual_matches = spark.sql(\n<br>\n", "SELECT m.match_id, m.toss_winner, m.toss_name, m.match_winner,<br>\n", "       CASE WHEN m.toss_winner = m.match_winner THEN 'Won' ELSE 'Lost' END AS match_outcome<br>\n", "FROM match m<br>\n", "WHERE m.toss_name IS NOT NULL<br>\n", "ORDER BY m.match_id<br>\n", ""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["toss_impact_individual_matches.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["COMMAND ----------"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import matplotlib.pyplot as plt"]}, {"cell_type": "markdown", "metadata": {}, "source": ["COMMAND ----------"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Assuming 'economical_bowlers_powerplay' is already executed and available as a Spark DataFrame"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["economical_bowlers_pd = economical_bowlers_powerplay.toPandas()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Visualizing using Matplotlib"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.figure(figsize=(12, 8))\n", "# Limiting to top 10 for clarity in the plot\n", "top_economical_bowlers = economical_bowlers_pd.nsmallest(10, 'avg_runs_per_ball')\n", "plt.bar(top_economical_bowlers['player_name'], top_economical_bowlers['avg_runs_per_ball'], color='skyblue')\n", "plt.xlabel('Bowler Name')\n", "plt.ylabel('Average Runs per Ball')\n", "plt.title('Most Economical Bowlers in Powerplay Overs (Top 10)')\n", "plt.xticks(rotation=45)\n", "plt.tight_layout()\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["COMMAND ----------"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import seaborn as sns\n", "     "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["toss_impact_pd = toss_impact_individual_matches.toPandas()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Creating a countplot to show win/loss after winning toss"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.figure(figsize=(10, 6))\n", "sns.countplot(x='toss_winner', hue='match_outcome', data=toss_impact_pd)\n", "plt.title('Impact of Winning Toss on Match Outcomes')\n", "plt.xlabel('Toss Winner')\n", "plt.ylabel('Number of Matches')\n", "plt.legend(title='Match Outcome')\n", "plt.xticks(rotation=45)\n", "plt.tight_layout()\n", "plt.show()\n", "     "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["     \n", "     "]}, {"cell_type": "markdown", "metadata": {}, "source": ["COMMAND ----------"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Execute SQL Query"]}, {"cell_type": "markdown", "metadata": {}, "source": ["scores_by_venue = spark.sql(\n<br>\n", "SELECT venue_name, AVG(total_runs) AS average_score, MAX(total_runs) AS highest_score<br>\n", "FROM (<br>\n", "    SELECT ball_by_ball.match_id, match.venue_name, SUM(runs_scored) AS total_runs<br>\n", "    FROM ball_by_ball<br>\n", "    JOIN match ON ball_by_ball.match_id = match.match_id<br>\n", "    GROUP BY ball_by_ball.match_id, match.venue_name<br>\n", ")<br>\n", "GROUP BY venue_name<br>\n", "ORDER BY average_score DESC<br>\n", ""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["     "]}, {"cell_type": "markdown", "metadata": {}, "source": ["Convert to Pandas DataFrame"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["scores_by_venue_pd = scores_by_venue.toPandas()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Plot"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.figure(figsize=(14, 8))\n", "sns.barplot(x='average_score', y='venue_name', data=scores_by_venue_pd)\n", "plt.title('Distribution of Scores by Venue')\n", "plt.xlabel('Average Score')\n", "plt.ylabel('Venue')\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["COMMAND ----------"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Execute SQL Query"]}, {"cell_type": "markdown", "metadata": {}, "source": ["dismissal_types = spark.sql(\n<br>\n", "SELECT out_type, COUNT(*) AS frequency<br>\n", "FROM ball_by_ball<br>\n", "WHERE out_type IS NOT NULL AND out_type != 'Not Applicable'<br>\n", "GROUP BY out_type<br>\n", "ORDER BY frequency DESC<br>\n", ""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["     "]}, {"cell_type": "markdown", "metadata": {}, "source": ["Convert to Pandas DataFrame"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["dismissal_types_pd = dismissal_types.toPandas()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Plot"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.figure(figsize=(12, 6))\n", "sns.barplot(x='frequency', y='out_type', data=dismissal_types_pd, palette='pastel')\n", "plt.title('Most Frequent Dismissal Types')\n", "plt.xlabel('Frequency')\n", "plt.ylabel('Dismissal Type')\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["COMMAND ----------"]}, {"cell_type": "markdown", "metadata": {}, "source": ["team_toss_win_performance = spark.sql(\n<br>\n", "SELECT team1, COUNT(*) AS matches_played, SUM(CASE WHEN toss_winner = match_winner THEN 1 ELSE 0 END) AS wins_after_toss<br>\n", "FROM match<br>\n", "WHERE toss_winner = team1<br>\n", "GROUP BY team1<br>\n", "ORDER BY wins_after_toss DESC<br>\n", ""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["     "]}, {"cell_type": "markdown", "metadata": {}, "source": ["Convert to Pandas DataFrame"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["team_toss_win_pd = team_toss_win_performance.toPandas()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Plot"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}